# âœ¦ Conrux AI â€” Elite Intelligence

<div align="center">

**A production-ready Expert AI Chatbot by [Blacifer](https://www.blacifer.com)**

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=flat-square&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.133%2B-009688?style=flat-square&logo=fastapi)
![Gemini](https://img.shields.io/badge/Google_Gemini-2.5_Flash-4285F4?style=flat-square&logo=google)
![License](https://img.shields.io/badge/License-MIT-gold?style=flat-square)

*Conversation meets artistry â€” a luxury AI chatbot with a production backend, 4-stage data pipeline, and an art-deco black-gold frontend.*

</div>

---

## ğŸ–¼ï¸ Preview

> **Frontend** â†’ art-deco black & gold theme â€¢ geometric canvas animations â€¢ custom SVG icons  
> **Backend** â†’ FastAPI REST API â€¢ 4-stage pipeline â€¢ multi-turn memory â€¢ rate limiting

---

## âœ¦ Features

| Capability | Details |
|---|---|
| ğŸ’¬ **Multi-turn Chat** | Session-based conversation memory with TTL eviction |
| ğŸ”­ **4-Stage Pipeline** | Input â†’ Context â†’ AI â†’ Output with per-stage timing |
| ğŸ–¼ï¸ **Vision Analysis** | Upload images (JPG, PNG, WEBP, GIF) for AI visual insight |
| ğŸ“„ **Document Processing** | PDF, DOCX, TXT, CSV, JSON, XLSX â€” up to 20 MB |
| ğŸ” **Optional Auth** | `X-API-Key` header auth, disable with no env var |
| âš¡ **Rate Limiting** | Configurable per-minute caps via `slowapi` |
| ğŸ—‚ï¸ **Session Management** | Thread-safe sessions with auto-expiry |
| ğŸ“‹ **Postman Collection** | Full API collection with automated tests |
| ğŸŒ **Luxury Frontend** | Black-gold art-deco HTML/CSS/JS served directly from FastAPI |

---

## ğŸ—ï¸ Project Structure

```
Conrux-AI/
â”œâ”€â”€ api/                        # FastAPI application layer
â”‚   â”œâ”€â”€ main.py                 # App factory â€” mounts frontend & routers
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ chat.py             # POST /chat, GET/DELETE /chat/history/{id}
â”‚   â”‚   â”œâ”€â”€ health.py           # GET /health, /info
â”‚   â”‚   â”œâ”€â”€ images.py           # POST /analyze/image
â”‚   â”‚   â””â”€â”€ documents.py        # POST /analyze/document
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic v2 request/response schemas
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ auth.py             # Optional X-API-Key authentication
â”‚       â””â”€â”€ logging_middleware.py  # Request ID + latency headers
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ gemini_client.py    # Gemini API client (legacy SDK, free-tier compatible)
â”‚   â”‚   â”œâ”€â”€ memory_manager.py   # Thread-safe in-memory conversation store + TTL
â”‚   â”‚   â””â”€â”€ session_manager.py  # Session lifecycle management
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ pipeline_manager.py # Orchestrates all 4 stages
â”‚   â”‚   â””â”€â”€ stages/
â”‚   â”‚       â”œâ”€â”€ input_stage.py  # Validation, sanitisation, injection detection
â”‚   â”‚       â”œâ”€â”€ context_stage.py # Load history, apply system prompt
â”‚   â”‚       â”œâ”€â”€ ai_stage.py     # Call Gemini, measure latency
â”‚   â”‚       â””â”€â”€ output_stage.py # Persist to memory, build result payload
â”‚   â”œâ”€â”€ ui/                     # Legacy Streamlit components (kept for reference)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ file_processor.py   # File reading, type detection
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py             # Pydantic-settings â€” all config from .env
â”‚
â”œâ”€â”€ frontend/                   # Luxury static frontend (served by FastAPI at /)
â”‚   â”œâ”€â”€ index.html              # Art-deco HTML with inline SVG icons
â”‚   â”œâ”€â”€ css/main.css            # Black-gold design system
â”‚   â””â”€â”€ js/app.js               # Dynamic chat, upload, geometric canvas
â”‚
â”œâ”€â”€ postman/
â”‚   â””â”€â”€ Chatbot_API_Collection.json   # Full Postman collection
â”‚
â”œâ”€â”€ assets/                     # Static assets (logo etc.)
â”œâ”€â”€ main.py                     # Legacy Streamlit entry (unused â€” see run_api.py)
â”œâ”€â”€ run_api.py                  # âœ… Quick-start launcher
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example                # All env variables documented
â””â”€â”€ .gitignore
```

---

## ğŸš€ Quick Start

### 1. Prerequisites

- Python **3.10+**
- A **Google Gemini API key** â†’ [Get one at Google AI Studio](https://aistudio.google.com/)

### 2. Clone & Install

```bash
git clone https://github.com/your-username/conrux-ai.git
cd conrux-ai

python -m venv venv
# Windows:  venv\Scripts\activate
# macOS/Linux: source venv/bin/activate

pip install -r requirements.txt
```

### 3. Configure Environment

```bash
cp .env.example .env
# Open .env and set your key:
# GEMINI_API_KEY=your_key_here
```

### 4. Run

```bash
python run_api.py
```

| URL | Description |
|---|---|
| `http://localhost:8000` | ğŸŒ Luxury frontend |
| `http://localhost:8000/docs` | ğŸ“‹ Swagger API docs |
| `http://localhost:8000/redoc` | ğŸ“– ReDoc API docs |

---

## ğŸ”§ Configuration Reference

All settings are loaded from `.env` (see `.env.example` for full reference):

| Variable | Default | Description |
|---|---|---|
| `GEMINI_API_KEY` | â€” | **Required.** Your Google Gemini API key |
| `CHATBOT_API_KEY` | â€” | Optional. Enables `X-API-Key` auth on all routes |
| `TEXT_MODEL` | `models/gemini-2.5-flash-lite` | Gemini model for text |
| `VISION_MODEL` | `models/gemini-2.5-flash-lite` | Gemini model for vision |
| `MAX_TOKENS` | `2048` | Max output tokens per response |
| `TEMPERATURE` | `0.7` | Model creativity (0.0â€“1.0) |
| `API_PORT` | `8000` | FastAPI server port |
| `SESSION_TTL_SECONDS` | `3600` | Session expiry (1 hour) |
| `MAX_CONTEXT_MESSAGES`| `20` | Message pairs kept in context |
| `MAX_FILE_SIZE_MB` | `20` | Upload limit |
| `RATE_LIMIT_CHAT` | `30/minute` | Chat endpoint rate limit |
| `LOG_LEVEL` | `INFO` | Logging verbosity |

> **Tip:** Check which models your API key supports by running:
> ```bash
> python -c "import google.generativeai as g, os; g.configure(api_key=os.getenv('GEMINI_API_KEY')); [print(m.name) for m in g.list_models() if 'generateContent' in m.supported_generation_methods]"
> ```

---

## ğŸ“¡ API Reference

Base URL: `http://localhost:8000/api/v1`

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/health` | Health check + Gemini connectivity |
| `GET` | `/info` | Model config & feature flags |
| `POST` | `/chat/session` | Create a new session |
| `POST` | `/chat` | Send a message (multi-turn) |
| `GET` | `/chat/history/{session_id}` | Get conversation history |
| `DELETE`| `/chat/history/{session_id}` | Clear history |
| `POST` | `/analyze/image` | Analyse an uploaded image |
| `POST` | `/analyze/document` | Analyse an uploaded document |

ğŸ“¦ **Postman:** Import `postman/Chatbot_API_Collection.json` â€” includes automated test assertions for every endpoint.

---

## ğŸ”„ Data Pipeline

Every chat message flows through 4 sequential stages:

```
User Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INPUT STAGE                      â”‚
â”‚  Validate length Â· Sanitise Â·       â”‚
â”‚  Detect prompt injection Â· Add ID   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONTEXT STAGE                    â”‚
â”‚  Load session history Â· Apply       â”‚
â”‚  system prompt Â· Trim context       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. AI STAGE                         â”‚
â”‚  Call Gemini Â· Multi-turn or        â”‚
â”‚  single turn Â· Measure latency      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. OUTPUT STAGE                     â”‚
â”‚  Persist to memory Â· Build result   â”‚
â”‚  payload Â· Update session           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         Structured JSON Response
```

---

## ğŸ› Troubleshooting

| Error | Cause | Fix |
|---|---|---|
| `404 NOT_FOUND: models/...` | Model not available on your API key | Run the model lister above; use a model from the output |
| `429 RESOURCE_EXHAUSTED` | Per-minute rate limit hit | Wait 60 seconds and retry |
| `No module named 'pydantic_settings'` | Missing dependency | `pip install pydantic-settings` |
| Frontend shows `{"detail":"Not Found"}` | Wrong working directory | Run from the `Chatbot/` root: `python run_api.py` |

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Make changes and add tests where applicable
4. Open a pull request

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

<div align="center">

**Made with âœ¦ by Blacifer**  
Powered by Google Gemini Â· Built with FastAPI

</div>